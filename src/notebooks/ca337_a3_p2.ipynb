{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNAp128t/FxjSJx9iOASbGR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"i8_s4-LGJBSM"},"outputs":[],"source":["test_set = [\n","    \"Oh, what a delightful experience! I can't contain my excitement, don't know what I enjoyed more, the rude service or the shocking food.\",\n","    \"The worst best restaurant I've ever been to. Terrible food and great service.\",\n","    \"Compared to a prison cafeteria, this restaurant is amazing! A true culinary wonderland.\",\n","    \"If you're into food that defies the laws of physics, this is the place to be.\",\n","    \"I can't say I didn't not dislike the food. It's not terrible, maybe.\",\n","    \"Not bad, but not great either. It's not like I'll never visit again, but there's no reason to rush back.\",\n","    \"Wow, just wow! This place is an absolute dream, if your dream is a nightmare.\",\n","    \"The chef here must have a Michelin-starred grandmother. The food is out of this world, literally.\",\n","    \"The ambience, if you can even call it that, adds a certain... charm to the dining experience.\",\n","    \"I'll give them points for trying. It's definitely a unique dining experience.\"\n","]"]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","\n","labels = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n","\n","vectorizer = CountVectorizer()\n","\n","X = vectorizer.fit_transform(test_set)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n","\n","logistic_classifier = LogisticRegression()\n","log = logistic_classifier.fit(X_train, y_train)\n","\n","logistic_predictions = logistic_classifier.predict(X_test)\n","\n","logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n","\n","print(f\"Logistic Regression Accuracy: {logistic_accuracy}\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ANrNGIl1KyQy","executionInfo":{"status":"ok","timestamp":1698412038816,"user_tz":-60,"elapsed":422,"user":{"displayName":"Cathal Ryan","userId":"02849422390361137072"}},"outputId":"298ae8af-61ba-40b8-dd3b-fa6378788f40"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Logistic Regression Accuracy: 0.5\n"]}]},{"cell_type":"code","source":["from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score\n","\n","tfidf_vectorizer = TfidfVectorizer(sublinear_tf=True, min_df=5, norm='l2', encoding='latin-1', ngram_range=(1, 2))\n","X = tfidf_vectorizer.fit_transform(test_set)\n","\n","X_train, X_test, y_train, y_test = train_test_split(X, labels, test_size=0.2, random_state=42)\n","\n","logistic_classifier = LogisticRegression()\n","logistic_classifier.fit(X_train, y_train)\n","\n","logistic_predictions = logistic_classifier.predict(X_test)\n","\n","logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n","\n","print(f\"Logistic Regression Accuracy with TF-IDF: {logistic_accuracy}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VT7WGh_gMfng","executionInfo":{"status":"ok","timestamp":1698412043874,"user_tz":-60,"elapsed":273,"user":{"displayName":"Cathal Ryan","userId":"02849422390361137072"}},"outputId":"e5b9fe12-caa8-43ba-ab93-adc18f08cfcf"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Logistic Regression Accuracy with TF-IDF: 0.5\n"]}]},{"cell_type":"code","source":["import nltk\n","nltk.download('vader_lexicon')\n","\n","from nltk.sentiment.vader import SentimentIntensityAnalyzer\n","from sklearn.model_selection import train_test_split\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.metrics import accuracy_score\n","import numpy as np\n","\n","test_set = [\n","    \"Oh, what a delightful experience! I can't contain my excitement, don't know what I enjoyed more, the rude service or the shocking food.\",\n","    \"The worst best restaurant I've ever been to. Terrible food and great service.\",\n","    \"Compared to a prison cafeteria, this restaurant is amazing! A true culinary wonderland.\",\n","    \"If you're into food that defies the laws of physics, this is the place to be.\",\n","    \"I can't say I didn't not dislike the food. It's not terrible, maybe.\",\n","    \"Not bad, but not great either. It's not like I'll never visit again, but there's no reason to rush back.\",\n","    \"Wow, just wow! This place is an absolute dream, if your dream is a nightmare.\",\n","    \"The chef here must have a Michelin-starred grandmother. The food is out of this world, literally.\",\n","    \"The ambience, if you can even call it that, adds a certain... charm to the dining experience.\",\n","    \"I'll give them points for trying. It's definitely a unique dining experience.\"\n","]\n","\n","labels = [0, 0, 0, 0, 0, 1, 1, 1, 1, 1]\n","\n","analyzer = SentimentIntensityAnalyzer()\n","\n","vader_scores = [analyzer.polarity_scores(review)['compound'] for review in test_set]\n","\n","vader_scores = np.array(vader_scores).reshape(-1, 1)\n","\n","X_with_vader = np.hstack((X.toarray(), vader_scores))\n","\n","X_train, X_test, y_train, y_test = train_test_split(X_with_vader, labels, test_size=0.2, random_state=42)\n","\n","logistic_classifier = LogisticRegression()\n","logistic_classifier.fit(X_train, y_train)\n","\n","logistic_predictions = logistic_classifier.predict(X_test)\n","\n","logistic_accuracy = accuracy_score(y_test, logistic_predictions)\n","\n","print(f\"Logistic Regression Accuracy with TF-IDF and VADER: {logistic_accuracy}\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_UW9vdmdPyw0","executionInfo":{"status":"ok","timestamp":1698412066881,"user_tz":-60,"elapsed":426,"user":{"displayName":"Cathal Ryan","userId":"02849422390361137072"}},"outputId":"9bcdc692-6718-4c85-a7d5-b9b519c459b4"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Logistic Regression Accuracy with TF-IDF and VADER: 0.5\n"]},{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package vader_lexicon to /root/nltk_data...\n","[nltk_data]   Package vader_lexicon is already up-to-date!\n"]}]},{"cell_type":"markdown","source":["I was unable to improve the accuracy using the two methods of:\n","\n","1. TF-IDF Vectorization:\n","I used TF-IDF vectorization instead of CountVectorizer and performed sentiment classification with logistic regression and adjusting hyperparameters. While this method did not work TF-IDF can give more weight to informative words and reduce the impact of common words, which can lead to better accuracy, especially when dealing with sentiment analysis.\n","\n","2. VADER Sentiment Lexicon:\n","I then decided to experiment with feature engineering and sentiment lexicons using VADER to create additional features for my model. My idea was to extract sentiment scores for each review and add these scores as additional features to the TF-IDF features. This combination of text-based and sentiment-based features could help improve accuracy, especially when dealing with mixed sentiment in reviews."],"metadata":{"id":"ldlQjbmSP8Fo"}}]}